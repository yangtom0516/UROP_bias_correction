{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b759f78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a34466b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import deepsensor\n",
    "import deepsensor.torch\n",
    "from deepsensor.train import set_gpu_default_device\n",
    "set_gpu_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d2d43d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepsensor.train import Trainer\n",
    "from deepsensor.model import ConvNP\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from deepsensor.data import DataProcessor, TaskLoader\n",
    "from tqdm import tqdm\n",
    "from scipy.special import sph_harm_y\n",
    "\n",
    "# Load first three files from dataset\n",
    "data_path = '/nfs/turbo/seas-dannes/urop-2024-bias/cfs-forecasts/cfs_2012-2023.zarr'\n",
    "\n",
    "# Open the Zarr store using Xarray\n",
    "ds0 = xr.open_zarr(data_path, consolidated=True)\n",
    "\n",
    "# Check the contents of the dataset\n",
    "ds0\n",
    "#ds = ds.sel(time=ds.time.dt.hour == 0)\n",
    "\n",
    "#ds = ds.sel(time=slice(\"2012-01-01\", \"2015-12-31\"))  # Select only the first three files\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee5f913d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2012-01-01T00:00:00.000000000' '2012-01-01T06:00:00.000000000'\n",
      " '2012-01-01T12:00:00.000000000' ... '2024-01-01T06:00:00.000000000'\n",
      " '2024-01-01T12:00:00.000000000' '2024-01-01T18:00:00.000000000']\n"
     ]
    }
   ],
   "source": [
    "ds = ds0.isel(lead=0, drop=True)\n",
    "ds = ds.sortby(\"time\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d574b8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10c5496b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2012-01-01T00:00:00.000000000' '2012-01-01T06:00:00.000000000'\n",
      " '2012-01-01T12:00:00.000000000' ... '2015-01-01T06:00:00.000000000'\n",
      " '2015-01-01T12:00:00.000000000' '2015-01-01T18:00:00.000000000']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41cc934b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 3GB\n",
      "Dimensions:            (time: 4206, latitude: 181, longitude: 360)\n",
      "Coordinates:\n",
      "  * latitude           (latitude) float64 1kB -90.0 -89.0 -88.0 ... 89.0 90.0\n",
      "  * longitude          (longitude) float64 3kB 0.0 1.0 2.0 ... 357.0 358.0 359.0\n",
      "  * time               (time) datetime64[ns] 34kB 2012-01-01 ... 2015-01-01T1...\n",
      "Data variables:\n",
      "    LHTFL_surface      (time, latitude, longitude) float32 1GB dask.array<chunksize=(1, 91, 180), meta=np.ndarray>\n",
      "    SHTFL_surface      (time, latitude, longitude) float32 1GB dask.array<chunksize=(1, 91, 180), meta=np.ndarray>\n",
      "    TMP_2maboveground  (time, latitude, longitude) float32 1GB dask.array<chunksize=(1, 91, 180), meta=np.ndarray>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "829de108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply bias correction function\n",
    "\n",
    "def spherical_harmonic_bias(data, l=2, m=1, amplitude=5):\n",
    "    lon = np.linspace(0, 2 * np.pi, data.shape[2])\n",
    "    lat = np.linspace(-np.pi / 2, np.pi / 2, data.shape[1])\n",
    "    lon_grid, lat_grid = np.meshgrid(lon, lat)\n",
    "    harmonics = np.real(sph_harm(m, l, lon_grid, lat_grid))\n",
    "    harmonics = amplitude * harmonics / np.max(np.abs(harmonics))\n",
    "    return harmonics[None, :, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a8709d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 7MB\n",
      "Dimensions:            (time: 9, latitude: 181, longitude: 360)\n",
      "Coordinates:\n",
      "  * latitude           (latitude) float64 1kB -90.0 -89.0 -88.0 ... 89.0 90.0\n",
      "  * longitude          (longitude) float64 3kB 0.0 1.0 2.0 ... 357.0 358.0 359.0\n",
      "  * time               (time) datetime64[ns] 72B 2012-01-01 ... 2012-01-03\n",
      "Data variables:\n",
      "    LHTFL_surface      (time, latitude, longitude) float32 2MB dask.array<chunksize=(1, 91, 180), meta=np.ndarray>\n",
      "    SHTFL_surface      (time, latitude, longitude) float32 2MB dask.array<chunksize=(1, 91, 180), meta=np.ndarray>\n",
      "    TMP_2maboveground  (time, latitude, longitude) float32 2MB dask.array<chunksize=(1, 91, 180), meta=np.ndarray>\n"
     ]
    }
   ],
   "source": [
    "print(ds.sel(time=slice(\"2012-01-01T00:00:00.000000000\", \"2012-01-03T00:00:00.000000000\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d36956ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataProcessor with normalisation params:\n",
      "{'LHTFL_surface': {'method': 'mean_std',\n",
      "                   'params': {'mean': 66.60301208496094,\n",
      "                              'std': 65.60218048095703}},\n",
      " 'SHTFL_surface': {'method': 'mean_std',\n",
      "                   'params': {'mean': 6.118175506591797,\n",
      "                              'std': 31.839258193969727}},\n",
      " 'TMP_2maboveground': {'method': 'mean_std',\n",
      "                       'params': {'mean': 276.7368469238281,\n",
      "                                  'std': 20.317398071289062}},\n",
      " 'coords': {'time': {'name': 'time'},\n",
      "            'x1': {'map': (-90.0, 269.0), 'name': 'latitude'},\n",
      "            'x2': {'map': (0.0, 359.0), 'name': 'longitude'}}}\n"
     ]
    }
   ],
   "source": [
    "data_processor = DataProcessor(x1_name=\"latitude\", x2_name=\"longitude\")\n",
    "_ = data_processor(ds.sel(time=slice(\"2012-01-01T00:00:00.000000000\", \"2012-01-31T00:00:00.000000000\")))\n",
    "ds_processed = data_processor(ds)\n",
    "print(data_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bba4839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 3GB\n",
      "Dimensions:            (time: 4206, x1: 181, x2: 360)\n",
      "Coordinates:\n",
      "  * time               (time) datetime64[ns] 34kB 2012-01-01 ... 2015-01-01T1...\n",
      "  * x1                 (x1) float64 1kB 0.0 0.002786 0.005571 ... 0.4986 0.5014\n",
      "  * x2                 (x2) float64 3kB 0.0 0.002786 0.005571 ... 0.9972 1.0\n",
      "Data variables:\n",
      "    LHTFL_surface      (time, x1, x2) float32 1GB dask.array<chunksize=(1, 91, 180), meta=np.ndarray>\n",
      "    SHTFL_surface      (time, x1, x2) float32 1GB dask.array<chunksize=(1, 91, 180), meta=np.ndarray>\n",
      "    TMP_2maboveground  (time, x1, x2) float32 1GB dask.array<chunksize=(1, 91, 180), meta=np.ndarray>\n"
     ]
    }
   ],
   "source": [
    "print(ds_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "892beddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_range = (\"2012-01-01\", \"2014-12-31\")\n",
    "val_range = (\"2015-01-01\", \"2015-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6a7426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6bbcb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5bc9216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaskLoader(1 context sets, 1 target sets)\n",
      "Context variable IDs: (('TMP_2maboveground',),)\n",
      "Target variable IDs: (('TMP_2maboveground',),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def add_bias_function(data, bias_function, **kwargs):\n",
    "    return data + bias_function(data, **kwargs)\n",
    "\n",
    "# Define TaskLoader\n",
    "biased_contexts = [\n",
    "    add_bias_function(ds_processed[\"TMP_2maboveground\"], spherical_harmonic_bias),\n",
    "    #add_bias_function(ds_processed[\"TMP_2maboveground\"], random_noise_bias),\n",
    "    #add_bias_function(ds_processed[\"TMP_2maboveground\"], linear_trend_bias),\n",
    "    #add_bias_function(ds_processed[\"TMP_2maboveground\"], periodic_step_bias),\n",
    "]\n",
    "\n",
    "task_loader = TaskLoader(\n",
    "    context=biased_contexts,  \n",
    "    target=ds_processed[\"TMP_2maboveground\"],\n",
    ")\n",
    "\n",
    "print(task_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7efb29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_yt inferred from TaskLoader: 1\n",
      "dim_aux_t inferred from TaskLoader: 0\n",
      "internal_density inferred from TaskLoader: 359\n",
      "encoder_scales inferred from TaskLoader: [np.float32(0.0013927576)]\n",
      "decoder_scale inferred from TaskLoader: 0.002785515320334262\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tasks\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Define the ConvNP model\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mConvNP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_processor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_yc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     21\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model)\n",
      "File \u001b[0;32m~/deepsensor_gpu_2/lib/python3.10/site-packages/plum/function.py:509\u001b[0m, in \u001b[0;36m_BoundFunction.__call__\u001b[0;34m(self, _, *args, **kw_args)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, _, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw_args):\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/deepsensor_gpu_2/lib/python3.10/site-packages/deepsensor/model/convnp.py:242\u001b[0m, in \u001b[0;36mConvNP.__init__\u001b[0;34m(self, data_processor, task_loader, verbose, *args, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_scale inferred from TaskLoader: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdecoder_scale\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m decoder_scale\n\u001b[0;32m--> 242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m \u001b[43mconstruct_neural_process\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_num_mixture_components()\n",
      "File \u001b[0;32m~/deepsensor_gpu_2/lib/python3.10/site-packages/deepsensor/model/nps.py:268\u001b[0m, in \u001b[0;36mconstruct_neural_process\u001b[0;34m(dim_x, dim_yc, dim_yt, dim_aux_t, dim_lv, conv_arch, unet_channels, unet_resize_convs, unet_resize_conv_interp_method, aux_t_mlp_layers, likelihood, unet_kernels, internal_density, encoder_scales, encoder_scales_learnable, decoder_scale, decoder_scale_learnable, num_basis_functions, epsilon)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBackend \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no default dtype.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 268\u001b[0m neural_process \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct_convgnp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_yc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_yc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_yt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_yt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_aux_t\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_aux_t\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_lv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_lv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlikelihood\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconv_arch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_arch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43munet_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43munet_channels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43munet_resize_convs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munet_resize_convs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43munet_resize_conv_interp_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munet_resize_conv_interp_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43maux_t_mlp_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maux_t_mlp_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43munet_kernels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munet_kernels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Use a stride of 1 for the first layer and 2 for all other layers\u001b[39;49;00m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43munet_strides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43munet_channels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoints_per_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minternal_density\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_scales\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_scales\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_scales_learnable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_scales_learnable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_scale_learnable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_scale_learnable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_basis_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_basis_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m neural_process, config\n",
      "File \u001b[0;32m~/deepsensor_gpu_2/lib/python3.10/site-packages/neuralprocesses/util.py:96\u001b[0m, in \u001b[0;36mwrapped_partial.<locals>.wrapped_f\u001b[0;34m(*args, **kw_args)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw_args):\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpartial_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpartial_kw_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deepsensor_gpu_2/lib/python3.10/site-packages/neuralprocesses/architectures/convgnp.py:300\u001b[0m, in \u001b[0;36mconstruct_convgnp\u001b[0;34m(dim_x, dim_y, dim_yc, dim_yt, dim_aux_t, points_per_unit, margin, likelihood, conv_arch, unet_channels, unet_kernels, unet_strides, unet_activations, unet_resize_convs, unet_resize_conv_interp_method, conv_receptive_field, conv_layers, conv_channels, num_basis_functions, dim_lv, lv_likelihood, encoder_scales, encoder_scales_learnable, decoder_scale, decoder_scale_learnable, aux_t_mlp_layers, divide_by_density, epsilon, transform, dtype, nps)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m         lv_conv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: x\n\u001b[0;32m--> 300\u001b[0m     conv \u001b[38;5;241m=\u001b[39m \u001b[43mnps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munet_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkernels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munet_kernels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munet_strides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactivations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munet_activations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresize_convs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munet_resize_convs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresize_conv_interp_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munet_resize_conv_interp_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseparable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msep\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_arch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mres\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_arch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m     receptive_field \u001b[38;5;241m=\u001b[39m conv\u001b[38;5;241m.\u001b[39mreceptive_field \u001b[38;5;241m/\u001b[39m points_per_unit\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m conv_arch:\n",
      "File \u001b[0;32m~/deepsensor_gpu_2/lib/python3.10/site-packages/neuralprocesses/torch/__init__.py:11\u001b[0m, in \u001b[0;36mcreate_init.<locals>.__init__\u001b[0;34m(self, *args, **kw_args)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw_args):\n\u001b[1;32m     10\u001b[0m     Module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deepsensor_gpu_2/lib/python3.10/site-packages/neuralprocesses/coders/nn.py:363\u001b[0m, in \u001b[0;36mUNet.__init__\u001b[0;34m(self, dim, in_channels, out_channels, channels, kernels, strides, activations, separable, residual, resize_convs, resize_conv_interp_method, dtype)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    353\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m Conv(\n\u001b[1;32m    354\u001b[0m                 in_channels\u001b[38;5;241m=\u001b[39mci,\n\u001b[1;32m    355\u001b[0m                 out_channels\u001b[38;5;241m=\u001b[39mco,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    359\u001b[0m                 dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    360\u001b[0m             )\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbefore_turn_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[0;32m--> 363\u001b[0m     [construct_before_turn_layer(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(channels))]\n\u001b[1;32m    364\u001b[0m )\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter_turn_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[1;32m    366\u001b[0m     [construct_after_turn_layer(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(channels))]\n\u001b[1;32m    367\u001b[0m )\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_linear \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mConv(\n\u001b[1;32m    369\u001b[0m     dim\u001b[38;5;241m=\u001b[39mdim,\n\u001b[1;32m    370\u001b[0m     in_channels\u001b[38;5;241m=\u001b[39mchannels[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    373\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    374\u001b[0m )\n",
      "File \u001b[0;32m~/deepsensor_gpu_2/lib/python3.10/site-packages/neuralprocesses/coders/nn.py:363\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    353\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m Conv(\n\u001b[1;32m    354\u001b[0m                 in_channels\u001b[38;5;241m=\u001b[39mci,\n\u001b[1;32m    355\u001b[0m                 out_channels\u001b[38;5;241m=\u001b[39mco,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    359\u001b[0m                 dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    360\u001b[0m             )\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbefore_turn_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[0;32m--> 363\u001b[0m     [\u001b[43mconstruct_before_turn_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(channels))]\n\u001b[1;32m    364\u001b[0m )\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter_turn_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[1;32m    366\u001b[0m     [construct_after_turn_layer(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(channels))]\n\u001b[1;32m    367\u001b[0m )\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_linear \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mConv(\n\u001b[1;32m    369\u001b[0m     dim\u001b[38;5;241m=\u001b[39mdim,\n\u001b[1;32m    370\u001b[0m     in_channels\u001b[38;5;241m=\u001b[39mchannels[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    373\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    374\u001b[0m )\n",
      "File \u001b[0;32m~/deepsensor_gpu_2/lib/python3.10/site-packages/neuralprocesses/coders/nn.py:279\u001b[0m, in \u001b[0;36mUNet.__init__.<locals>.construct_before_turn_layer\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    275\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrides[i]\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# Just a regular convolutional layer.\u001b[39;00m\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mConv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mci\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mco\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# This is a downsampling layer.\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreceptive_fields[i] \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;66;03m# Perform average pooling if the previous receptive field is odd.\u001b[39;00m\n",
      "File \u001b[0;32m~/deepsensor_gpu_2/lib/python3.10/site-packages/neuralprocesses/coders/nn.py:263\u001b[0m, in \u001b[0;36mUNet.__init__.<locals>.Conv\u001b[0;34m(stride, transposed, **kw_args)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transposed \u001b[38;5;129;01mand\u001b[39;00m stride \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    262\u001b[0m     kw_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_padding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stride \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m--> 263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransposed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransposed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deepsensor_gpu_2/lib/python3.10/site-packages/neuralprocesses/torch/nn.py:83\u001b[0m, in \u001b[0;36mConvNd\u001b[0;34m(dim, in_channels, out_channels, kernel, stride, dilation, groups, bias, transposed, output_padding, dtype)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     suffix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConv\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msuffix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdim\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43md\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdilation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deepsensor_gpu_2/lib/python3.10/site-packages/torch/nn/modules/conv.py:521\u001b[0m, in \u001b[0;36mConv2d.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    519\u001b[0m padding_ \u001b[38;5;241m=\u001b[39m padding \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(padding, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m _pair(padding)\n\u001b[1;32m    520\u001b[0m dilation_ \u001b[38;5;241m=\u001b[39m _pair(dilation)\n\u001b[0;32m--> 521\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_size_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdilation_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_pair\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deepsensor_gpu_2/lib/python3.10/site-packages/torch/nn/modules/conv.py:176\u001b[0m, in \u001b[0;36m_ConvNd.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_parameter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deepsensor_gpu_2/lib/python3.10/site-packages/torch/nn/modules/conv.py:182\u001b[0m, in \u001b[0;36m_ConvNd.reset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreset_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;66;03m# uniform(-1/sqrt(k), 1/sqrt(k)), where k = weight.size(1) * prod(*kernel_size)\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;66;03m# For more details see: https://github.com/pytorch/pytorch/issues/15314#issuecomment-477448573\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m     \u001b[43minit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkaiming_uniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    184\u001b[0m         fan_in, _ \u001b[38;5;241m=\u001b[39m init\u001b[38;5;241m.\u001b[39m_calculate_fan_in_and_fan_out(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n",
      "File \u001b[0;32m~/deepsensor_gpu_2/lib/python3.10/site-packages/torch/nn/init.py:500\u001b[0m, in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity, generator)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Fill the input `Tensor` with values using a Kaiming uniform distribution.\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03mThe method is described in `Delving deep into rectifiers: Surpassing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;124;03m    pass in a transposed weight matrix, i.e. ``nn.init.kaiming_uniform_(w.T, ...)``.\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39moverrides\u001b[38;5;241m.\u001b[39mhas_torch_function_variadic(tensor):\n\u001b[0;32m--> 500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkaiming_uniform_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnonlinearity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnonlinearity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mshape:\n\u001b[1;32m    511\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing zero-element tensors is a no-op\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/deepsensor_gpu_2/lib/python3.10/site-packages/torch/overrides.py:1720\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[1;32m   1717\u001b[0m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[1;32m   1718\u001b[0m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[0;32m-> 1720\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1721\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1722\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/deepsensor_gpu_2/lib/python3.10/site-packages/torch/utils/_device.py:104\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deepsensor_gpu_2/lib/python3.10/site-packages/torch/nn/init.py:518\u001b[0m, in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity, generator)\u001b[0m\n\u001b[1;32m    516\u001b[0m bound \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m3.0\u001b[39m) \u001b[38;5;241m*\u001b[39m std  \u001b[38;5;66;03m# Calculate uniform bounds from standard deviation\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "def gen_tasks(dates, progress=True):\n",
    "    tasks = []\n",
    "    for date in tqdm(dates):\n",
    "        date = np.datetime64(date)  # Ensure consistent datetime format\n",
    "        try:\n",
    "            task = task_loader(date, context_sampling=\"all\", target_sampling=\"all\")  \n",
    "            tasks.append(task)\n",
    "        except KeyError:\n",
    "            print(f\"Skipping date {date} as it is not found in dataset.\")\n",
    "        sys.stdout.flush()\n",
    "    print(f\"Finished generating {len(tasks)} tasks.\")\n",
    "    return tasks\n",
    "\n",
    "\n",
    "# Define the ConvNP model\n",
    "model = ConvNP(data_processor, task_loader, dim_yc=(1,))\n",
    "\n",
    "# Train the model\n",
    "trainer = Trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f4c98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"time\"] = pd.to_datetime(ds[\"time\"].values).strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e46358",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b00d9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "val_rmses = []\n",
    "train_rmses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6640f58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_val_rmse(model, val_tasks):\n",
    "    errors = []\n",
    "    target_var_ID = task_loader.target_var_IDs[0][0]  # assume 1st target set and 1D\n",
    "    for task in val_tasks:\n",
    "        mean = data_processor.map_array(model.mean(task), target_var_ID, unnorm=True)\n",
    "        true = data_processor.map_array(task[\"Y_t\"][0], target_var_ID, unnorm=True)\n",
    "        errors.extend(np.abs(mean - true))\n",
    "    return np.sqrt(np.mean(np.concatenate(errors) ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7286cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_train_rmse(model, train_tasks):\n",
    "    errors = []\n",
    "    context_var_ID = task_loader.context_var_IDs[0][0]  # assume 1st target set and 1D\n",
    "    for task in train_tasks:\n",
    "        mean = data_processor.map_array(model.mean(task), context_var_ID, unnorm=True)\n",
    "        true = data_processor.map_array(task[\"Y_t\"][0], context_var_ID, unnorm=True)\n",
    "        errors.extend(np.abs(mean - true))\n",
    "    return np.sqrt(np.mean(np.concatenate(errors) ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532de9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dates = pd.date_range(val_range[0], val_range[1])\n",
    "val_tasks = gen_tasks(val_dates)\n",
    "_ = model(val_tasks[0])\n",
    "print(f\"Model has {deepsensor.backend.nps.num_params(model.model):,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3c0bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "#deepsensor_folder = \"/home/whruiray/deepsensor_config/\"\n",
    "\n",
    "\n",
    "val_rmse_best = np.inf\n",
    "train_rmse_best = np.inf\n",
    "\n",
    "\n",
    "trainer = Trainer(model, lr=5e-5)\n",
    "train_tasks = gen_tasks(pd.date_range(train_range[0], train_range[1]), progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70f278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(10)):\n",
    "    #train_tasks = gen_tasks(pd.date_range(train_range[0], train_range[1]), progress=False)\n",
    "    \n",
    "    print(f\"Training batch for Epoch {epoch+1} started...\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    batch_losses = trainer(train_tasks)\n",
    "    \n",
    "    \n",
    "    losses.append(np.mean(batch_losses))\n",
    "    print(f\"Training batch for Epoch {epoch+1} complete...\")\n",
    "    sys.stdout.flush()\n",
    "   \n",
    "    train_rmses.append(compute_train_rmse(model, train_tasks))\n",
    "    print(f\"Epoch {epoch+1} - Loss: {losses[-1]:.4f}, Validation RMSE: {train_rmses[-1]:.4f}\")\n",
    "    print(f\"Epoch {epoch+1} completed in {time.time()} seconds.\")\n",
    "    sys.stdout.flush()\n",
    "    if train_rmses[-1] < train_rmse_best:\n",
    "        train_rmse_best = train_rmses[-1]\n",
    "\n",
    "    val_rmses.append(compute_val_rmse(model, val_tasks))\n",
    "    print(f\"Epoch {epoch+1} - Loss: {losses[-1]:.4f}, Validation RMSE: {val_rmses[-1]:.4f}\")\n",
    "    print(f\"Epoch {epoch+1} completed in {time.time()} seconds.\")\n",
    "    sys.stdout.flush()\n",
    "    if val_rmses[-1] < val_rmse_best:\n",
    "        val_rmse_best = val_rmses[-1]\n",
    "\n",
    "        #model.save(deepsensor_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4a3f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].plot(losses)\n",
    "axes[1].plot(val_rmses)\n",
    "_ = axes[0].set_xlabel(\"Epoch\")\n",
    "_ = axes[1].set_xlabel(\"Epoch\")\n",
    "_ = axes[0].set_title(\"Training loss\")\n",
    "_ = axes[1].set_title(\"Validation RMSE\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig/spherical_bias_loss_and_rmse.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb4462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training metrics with adjusted scales\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Smooth the loss values (using simple moving average)\n",
    "window_size = 5\n",
    "smoothed_losses = np.convolve(losses, np.ones(window_size)/window_size, mode='valid')\n",
    "\n",
    "# Plot training loss\n",
    "ax1.plot(range(len(smoothed_losses)), smoothed_losses, 'b-', label='Training Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss', color='b')\n",
    "ax1.tick_params('y', colors='b')\n",
    "\n",
    "# Create a second y-axis for validation RMSE\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(range(len(val_rmses)), val_rmses, 'r-', label='Validation RMSE')\n",
    "ax2.set_ylabel('RMSE', color='r')\n",
    "ax2.tick_params('y', colors='r')\n",
    "\n",
    "# Adjust scales to show downward trend\n",
    "if len(losses) > 0:\n",
    "    loss_min, loss_max = min(smoothed_losses), max(smoothed_losses)\n",
    "    ax1.set_ylim(loss_min - 0.1*(loss_max-loss_min), loss_max + 0.1*(loss_max-loss_min))\n",
    "\n",
    "if len(val_rmses) > 0:\n",
    "    rmse_min, rmse_max = min(val_rmses), max(val_rmses)\n",
    "    ax2.set_ylim(rmse_min - 0.1*(rmse_max-rmse_min), rmse_max + 0.1*(rmse_max-rmse_min))\n",
    "\n",
    "plt.title('Training Loss and Validation RMSE')\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"fig/spherical_bias_metrics.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6c2ba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import deepsensor\n",
    "from deepsensor import plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select a sample date for visualization\n",
    "sample_date = \"2012-01-01\"\n",
    "sample_task = task_loader(sample_date, context_sampling=\"all\", target_sampling=\"all\")\n",
    "\n",
    "task_loader_spherical_barmonic_bias = TaskLoader(\n",
    "    context=biased_contexts,\n",
    "    target=ds_processed[\"TMP_2maboveground\"],\n",
    ")\n",
    "# Plot context (biased) and target (original) data\n",
    "fig = deepsensor.plot.task(sample_task, task_loader=task_loader_spherical_barmonic_bias)\n",
    "fig.savefig(\"fig/constant_sample_context_target_plot.png\")\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c03859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Choose the target date for prediction\n",
    "target_date = \"2016-01-15\"  # Example date in the 2016-2020 range\n",
    "\n",
    "# Step 2: Load the task for the target date (context and target data)\n",
    "task = task_loader(target_date, context_sampling=\"all\", target_sampling=\"all\")\n",
    "\n",
    "# Step 3: Run the model to get predictions\n",
    "# Note that X_t is just passed as ds. It gets the xarray structure from ds. \n",
    "pred_val = model.predict(task, X_t=ds)  # Just pass the task object\n",
    "\n",
    "# Step 4: Extract the relevant variable for predictions (e.g., 'APCP_surface' or 'TMP_2maboveground')\n",
    "# Assuming 'TMP_2maboveground' is the variable you're predicting\n",
    "predxr = pred_val['TMP_2maboveground']\n",
    "\n",
    "# Step 5: Plot the mean prediction\n",
    "predxr['mean'].plot(cmap='viridis')  # Plot mean prediction\n",
    "plt.title(f\"Prediction for {target_date}\")\n",
    "plt.savefig(f\"fig/prediction_for_spherical_bias_{target_date}_mean.png\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Step 6: Plot the standard deviation as well\n",
    "predxr['std'].plot(cmap='viridis')  # Plot standard deviation\n",
    "plt.title(f\"Standard Deviation for {target_date}\")\n",
    "plt.savefig(f\"fig/prediction_for_spherical_bias_{target_date}_std.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03040d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2956e343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5fa992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepsensor_gpu_2)",
   "language": "python",
   "name": "deepsensor_gpu_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
